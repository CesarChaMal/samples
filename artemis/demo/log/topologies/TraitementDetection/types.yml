tosca_definitions_version: alien_dsl_2_0_0

metadata:
  template_name: TraitementDetection
  template_version: 2.1.0-SNAPSHOT
  template_author: admin

description: ""

imports:
  - artemis.kafka.topic:2.1.0-SNAPSHOT
  - tosca-normative-types:1.0.0-ALIEN20
  - artemis.kafka.pub:2.1.0-SNAPSHOT
  - artemis.hadoop.pub:2.1.0-SNAPSHOT
  - artemis.demo.log.collecte:2.1.0-SNAPSHOT
  - artemis.demo.log.detection:2.1.0-SNAPSHOT
  - artemis.demo.log.ecriture:2.1.0-SNAPSHOT
  - artemis.zookeeper.pub:2.1.0-SNAPSHOT
  - artemis.demo.common:2.1.0-SNAPSHOT
  - artemis.demo.log.traitement:2.1.0-SNAPSHOT
  - artemis.hadoop.repository:2.1.0-SNAPSHOT
  - artemis.elasticsearch.pub:2.1.0-SNAPSHOT
  - artemis.spark.pub:2.1.0-SNAPSHOT

topology_template:
  inputs:
    RAM_Ecriture_Logs:
      type: integer
      required: true
      default: 1
    CPU_Traitement:
      type: integer
      required: true
      default: 1
    RAM_Detection:
      type: integer
      required: true
      default: 1
    RAM_Traitement:
      type: integer
      required: true
      default: 1
    Seuil_Detection_Attaque_DoS:
      type: integer
      required: true
      default: 10
    CPU_Detection:
      type: integer
      required: true
      default: 1
    CPU_Ecriture_Logs:
      type: integer
      required: true
      default: 1
    RAM_Ecriture_Detection:
      type: integer
      required: true
      default: 1
    CPU_Ecriture_Detection:
      type: integer
      required: true
      default: 1
    RAM_Collecte:
      type: integer
      required: true
      default: 1
    CPU_Collecte:
      type: integer
      required: true
      default: 1
  input_artifacts:
    jar_file:
        type: tosca.artifacts.File
  node_templates:
    EspaceDeStockage_LogsPropres:
      metadata:
        a4c_edit_x: 173
        a4c_edit_y: 398
      type: artemis.elasticsearch.pub.nodes.ElasticSearchService
      capabilities:
        elasticsearch:
          properties:
            port: 9300
            protocol: tcp
            secure: false
            network_name: PRIVATE
            initiator: source
        http:
          properties:
            port: 9200
            protocol: http
            secure: false
            network_name: PRIVATE
            initiator: source
    Source_Logs:
      metadata:
        a4c_edit_x: 191
        a4c_edit_y: "-165"
      type: artemis.demo.common.nodes.RepertoireHDFS
    CollecteLogBatch:
      metadata:
        a4c_edit_x: "-119"
        a4c_edit_y: "-141"
      type: artemis.demo.log.collecte.nodes.CollecteLogBatch
      properties:
        class_name: "demo.MockCollector"
        memory: { get_input: RAM_Collecte }
        cores: { get_input: CPU_Collecte }
      requirements:
        - traitementConnect2HdfsMoyenDeStockageHdfsHdfs_endpoint:
            type_requirement: hdfs
            node: MoyenDeStockageHDFS
            capability: artemis.hadoop.pub.capabilities.HDFSEndpoint
            relationship: artemis.demo.common.relationships.TraitementConnect2Hdfs
        - traitementConnect2SparkMoteurExecutionSparkSpark_endpoint:
            type_requirement: spark
            node: MoteurExecutionSpark
            capability: artemis.spark.pub.capabilities.SparkEndpoint
            relationship: artemis.demo.common.relationships.TraitementConnect2Spark
        - sparkApp2HdfsRepoInputSourceLogsHdfs_repository:
            type_requirement: input_repository
            node: Source_Logs
            capability: artemis.hadoop.pub.capabilities.HdfsRepository
            relationship: artemis.demo.common.relationships.SparkApp2HdfsRepoInput
        - sparkApp2HdfsRepoOutputEspaceTempCollecteTraitementHdfs_repository:
            type_requirement: output_repository
            node: Espace_Temp_Collecte_Traitement
            capability: artemis.hadoop.pub.capabilities.HdfsRepository
            relationship: artemis.demo.common.relationships.SparkApp2HdfsRepoOutput
        - sparkApp2HdfsRepoErrorEspaceTempErreursHdfs_repository:
            type_requirement: error_repository
            node: Espace_Temp_Erreurs
            capability: artemis.hadoop.pub.capabilities.HdfsRepository
            relationship: artemis.demo.common.relationships.SparkApp2HdfsRepoError
      artifacts:
        jar_file:
          file: { get_input_artifact: jar_file }
          type: tosca.artifacts.File
    DetectionLogBatch:
      metadata:
        a4c_edit_x: "-123"
        a4c_edit_y: 213
      type: artemis.demo.log.detection.nodes.DetectionLogBatch
      properties:
        class_name: "demo.MockAnalyser"
        threshold: { get_input: Seuil_Detection_Attaque_DoS }
        memory: { get_input: RAM_Detection }
        cores: { get_input: CPU_Detection }
      requirements:
        - traitementConnect2HdfsMoyenDeStockageHdfsHdfs_endpoint:
            type_requirement: hdfs
            node: MoyenDeStockageHDFS
            capability: artemis.hadoop.pub.capabilities.HDFSEndpoint
            relationship: artemis.demo.common.relationships.TraitementConnect2Hdfs
        - traitementConnect2SparkMoteurExecutionSparkSpark_endpoint:
            type_requirement: spark
            node: MoteurExecutionSpark
            capability: artemis.spark.pub.capabilities.SparkEndpoint
            relationship: artemis.demo.common.relationships.TraitementConnect2Spark
        - dependsOnCollecteLogBatchFeature:
            type_requirement: dependency
            node: CollecteLogBatch
            capability: tosca.capabilities.Node
            relationship: tosca.relationships.DependsOn
        - sparkApp2HdfsRepoOutputEspaceTempDetectEcritureHdfs_repository:
            type_requirement: output_repository
            node: Espace_Temp_Detect_Ecriture
            capability: artemis.hadoop.pub.capabilities.HdfsRepository
            relationship: artemis.demo.common.relationships.SparkApp2HdfsRepoOutput
        - sparkApp2HdfsRepoInputEspaceTempCollecteTraitementHdfs_repository:
            type_requirement: input_repository
            node: Espace_Temp_Collecte_Traitement
            capability: artemis.hadoop.pub.capabilities.HdfsRepository
            relationship: artemis.demo.common.relationships.SparkApp2HdfsRepoInput
      artifacts:
        jar_file:
          file: { get_input_artifact: jar_file }
          type: tosca.artifacts.File
    TraitementLogBatch:
      metadata:
        a4c_edit_x: "-120"
        a4c_edit_y: 8
      type: artemis.demo.log.traitement.nodes.TraitementLogBatch
      properties:
        class_name: "demo.MockParser"
        memory: { get_input: RAM_Traitement }
        cores: { get_input: CPU_Traitement }
      requirements:
        - sparkApp2HdfsRepoOutputEspaceTempTraitementEcritureHdfs_repository:
            type_requirement: output_repository
            node: Espace_Temp_Traitement_Ecriture
            capability: artemis.hadoop.pub.capabilities.HdfsRepository
            relationship: artemis.demo.common.relationships.SparkApp2HdfsRepoOutput
        - traitementConnect2HdfsMoyenDeStockageHdfsHdfs_endpoint:
            type_requirement: hdfs
            node: MoyenDeStockageHDFS
            capability: artemis.hadoop.pub.capabilities.HDFSEndpoint
            relationship: artemis.demo.common.relationships.TraitementConnect2Hdfs
        - traitementConnect2SparkMoteurExecutionSparkSpark_endpoint:
            type_requirement: spark
            node: MoteurExecutionSpark
            capability: artemis.spark.pub.capabilities.SparkEndpoint
            relationship: artemis.demo.common.relationships.TraitementConnect2Spark
        - dependsOnCollecteLogBatchFeature:
            type_requirement: dependency
            node: CollecteLogBatch
            capability: tosca.capabilities.Node
            relationship: tosca.relationships.DependsOn
        - sparkApp2HdfsRepoInputEspaceTempCollecteTraitementHdfs_repository:
            type_requirement: input_repository
            node: Espace_Temp_Collecte_Traitement
            capability: artemis.hadoop.pub.capabilities.HdfsRepository
            relationship: artemis.demo.common.relationships.SparkApp2HdfsRepoInput
      artifacts:
        jar_file:
          file: { get_input_artifact: jar_file }
          type: tosca.artifacts.File
    MoteurExecutionSpark:
      metadata:
        a4c_edit_x: 534
        a4c_edit_y: "-73"
      type: artemis.demo.common.nodes.MoteurExecutionSpark
      capabilities:
        spark_endpoint:
          properties:
            port: 6066
            protocol: spark
            secure: false
            network_name: PRIVATE
            initiator: source
        http_endpoint:
          properties:
            port: 8080
            protocol: http
            secure: false
            network_name: PRIVATE
            initiator: source
    MoyenDeStockageHDFS:
      metadata:
        a4c_edit_x: 553
        a4c_edit_y: 83
      type: artemis.demo.common.nodes.MoyenDeStockageHDFS
      capabilities:
        hdfs_endpoint:
          properties:
            port: 9000
            protocol: hdfs
            secure: false
            network_name: PRIVATE
            initiator: source
    Espace_Temp_Detect_Ecriture:
      metadata:
        a4c_edit_x: 181
        a4c_edit_y: 250
      type: artemis.demo.common.nodes.RepertoireHDFSTemp
      properties:
        path: "/data/sandbox/temp"
      requirements:
        - hdfsRepositoryConnectToHdfsServiceMoyenDeStockageHdfsHdfs_endpoint:
            type_requirement: hdfs
            node: MoyenDeStockageHDFS
            capability: artemis.hadoop.pub.capabilities.HDFSEndpoint
            relationship: artemis.hadoop.repository.relationships.HdfsRepositoryConnectToHDFSService
    Ecriture_Traitement:
      metadata:
        a4c_edit_x: "-122"
        a4c_edit_y: 109
      type: artemis.demo.log.ecriture.nodes.EcritureLogBatch
      properties:
        class_name: "demo.MockWriter"
        index_name: "index_demo_logsbruts"
        type_name: "log_brut"
        memory: { get_input: RAM_Ecriture_Logs }
        cores: { get_input: CPU_Ecriture_Logs }
      requirements:
        - traitementConnect2HdfsMoyenDeStockageHdfsHdfs_endpoint:
            type_requirement: hdfs
            node: MoyenDeStockageHDFS
            capability: artemis.hadoop.pub.capabilities.HDFSEndpoint
            relationship: artemis.demo.common.relationships.TraitementConnect2Hdfs
        - dependsOnTraitementLogBatchFeature:
            type_requirement: dependency
            node: TraitementLogBatch
            capability: tosca.capabilities.Node
            relationship: tosca.relationships.DependsOn
        - traitementConnect2SparkMoteurExecutionSparkSpark_endpoint:
            type_requirement: spark
            node: MoteurExecutionSpark
            capability: artemis.spark.pub.capabilities.SparkEndpoint
            relationship: artemis.demo.common.relationships.TraitementConnect2Spark
        - sparkApp2HdfsRepoInputEspaceTempTraitementEcritureHdfs_repository:
            type_requirement: input_repository
            node: Espace_Temp_Traitement_Ecriture
            capability: artemis.hadoop.pub.capabilities.HdfsRepository
            relationship: artemis.demo.common.relationships.SparkApp2HdfsRepoInput
        - ecriture2ElasticsearchEspaceDeStockageLogsPropresHttp:
            type_requirement: stockage
            node: EspaceDeStockage_LogsPropres
            capability: artemis.elasticsearch.pub.capabilities.ElasticSearchRestAPI
            relationship: artemis.demo.log.ecriture.relationships.Ecriture2Elasticsearch
      artifacts:
        jar_file:
          file: { get_input_artifact: jar_file }
          type: tosca.artifacts.File
    Ecriture_Detection:
      metadata:
        a4c_edit_x: "-123"
        a4c_edit_y: 313
      type: artemis.demo.log.ecriture.nodes.EcritureLogBatch
      properties:
        class_name: "demo.MockWriter"
        index_name: "index_demo_detection"
        type_name: "log_detection"
        memory: { get_input: RAM_Ecriture_Detection }
        cores: { get_input: CPU_Ecriture_Detection }
      requirements:
        - traitementConnect2HdfsMoyenDeStockageHdfsHdfs_endpoint:
            type_requirement: hdfs
            node: MoyenDeStockageHDFS
            capability: artemis.hadoop.pub.capabilities.HDFSEndpoint
            relationship: artemis.demo.common.relationships.TraitementConnect2Hdfs
        - traitementConnect2SparkMoteurExecutionSparkSpark_endpoint:
            type_requirement: spark
            node: MoteurExecutionSpark
            capability: artemis.spark.pub.capabilities.SparkEndpoint
            relationship: artemis.demo.common.relationships.TraitementConnect2Spark
        - sparkApp2HdfsRepoInputEspaceTempDetectEcritureHdfs_repository:
            type_requirement: input_repository
            node: Espace_Temp_Detect_Ecriture
            capability: artemis.hadoop.pub.capabilities.HdfsRepository
            relationship: artemis.demo.common.relationships.SparkApp2HdfsRepoInput
        - dependsOnDetectionLogBatchFeature:
            type_requirement: dependency
            node: DetectionLogBatch
            capability: tosca.capabilities.Node
            relationship: tosca.relationships.DependsOn
        - ecriture2ElasticsearchEspaceDeStockageLogsPropresHttp:
            type_requirement: stockage
            node: EspaceDeStockage_LogsPropres
            capability: artemis.elasticsearch.pub.capabilities.ElasticSearchRestAPI
            relationship: artemis.demo.log.ecriture.relationships.Ecriture2Elasticsearch
      artifacts:
        jar_file:
          file: { get_input_artifact: jar_file }
          type: tosca.artifacts.File
    Espace_Temp_Collecte_Traitement:
      metadata:
        a4c_edit_x: 183
        a4c_edit_y: "-35"
      type: artemis.demo.common.nodes.RepertoireHDFSTemp
      properties:
        path: "/data/sandbox/temp"
      requirements:
        - hdfsRepositoryConnectToHdfsServiceMoyenDeStockageHdfsHdfs_endpoint:
            type_requirement: hdfs
            node: MoyenDeStockageHDFS
            capability: artemis.hadoop.pub.capabilities.HDFSEndpoint
            relationship: artemis.hadoop.repository.relationships.HdfsRepositoryConnectToHDFSService
    Espace_Temp_Traitement_Ecriture:
      metadata:
        a4c_edit_x: 172
        a4c_edit_y: 106
      type: artemis.demo.common.nodes.RepertoireHDFSTemp
      properties:
        path: "/data/sandbox/temp"
      requirements:
        - hdfsRepositoryConnectToHdfsServiceMoyenDeStockageHdfsHdfs_endpoint:
            type_requirement: hdfs
            node: MoyenDeStockageHDFS
            capability: artemis.hadoop.pub.capabilities.HDFSEndpoint
            relationship: artemis.hadoop.repository.relationships.HdfsRepositoryConnectToHDFSService
    Espace_Temp_Erreurs:
      metadata:
        a4c_edit_x: 178
        a4c_edit_y: 32
      type: artemis.demo.common.nodes.RepertoireHDFSTemp
      properties:
        path: "/data/sandbox/temp"
      requirements:
        - hdfsRepositoryConnectToHdfsServiceMoyenDeStockageHdfsHdfs_endpoint:
            type_requirement: hdfs
            node: MoyenDeStockageHDFS
            capability: artemis.hadoop.pub.capabilities.HDFSEndpoint
            relationship: artemis.hadoop.repository.relationships.HdfsRepositoryConnectToHDFSService
